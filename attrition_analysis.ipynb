{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WAF Data Challenge",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysxcTOIGiZOb"
      },
      "source": [
        "## **Setup and Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jUk3uAilAh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno\n",
        "import random\n",
        "\n",
        "from scipy.io import arff\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LogisticRegression, \\\n",
        "LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, \\\n",
        "f1_score, roc_curve, auc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5rfX98yjVnD"
    },
      "source": [
        "### **Loading Data into Your Environment**\n",
        "1.   Open the file browsing menu by clicking on the tab with a right pointing arrow\n",
        "2.   Upload the csv file containing the employee data to \\content (the default directory)\n",
        "3.   Run the code block below.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUnUVfMSBt-"
      },
      "source": [
        "#load data into dataframe\n",
        "df = pd.read_csv('./employee_attrition.csv')\n",
        "\n",
        "#coerce object to categorical data\n",
        "cat_cols = []\n",
        "for t, s in df.iteritems():\n",
        "  if str(s.dtype) == 'object' and t != 'Over18' and t != 'Attrition':\n",
        "    df[t] = df[t].astype('category')\n",
        "    cat_cols.append(t)\n",
        "\n",
        "#reorder columns\n",
        "df = df[[c for c in df if c not in ['Attrition', 'Over18']] + ['Attrition']]\n",
        "y = df.iloc[:, -1].values\n",
        "y = np.vectorize(lambda x: 1 if x == \"Yes\" else 0)(y)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "#encode columns\n",
        "X = pd.get_dummies(X, columns=cat_cols)\n",
        "features = [t for t, s in X.iteritems()]\n",
        "X = X.values\n",
        "c_weight = {0: 1, 1: 5}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUqF43QZkAAs"
      },
      "source": [
        "### **Creating Training and Test Sets**\n",
        "We assign 70% of the data into the training set and 30% into the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RquBQYEsld2_"
      },
      "source": [
        "X_norm = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Seperate negative and positive examples\n",
        "X_pos = X[y == 1]\n",
        "y_pos = y[y == 1]\n",
        "X_neg = X[y == 0]\n",
        "y_neg = y[y == 0]\n",
        "\n",
        "# Split full data into training and test sets\n",
        "pos = int(len(y_pos) * 0.7)\n",
        "neg = int(len(y_neg) * 0.7)\n",
        "\n",
        "X_train = np.concatenate((X_neg[:neg], X_pos[:pos]))\n",
        "y_train = np.concatenate((y_neg[:neg], y_pos[:pos]))\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test = np.concatenate((X_neg[neg:], X_pos[pos:]))\n",
        "y_test = np.concatenate((y_neg[neg:], y_pos[pos:]))\n",
        "X_test, y_test = shuffle(X_test, y_test)\n",
        "X_test = StandardScaler().fit_transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlxW3Ex1khsI"
      },
      "source": [
        "## **Utility Functions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbweFKtLnu0e"
      },
      "source": [
        "# Plot training results\n",
        "def plot_line_graph(x_vals, y_vals_1, y_vals_2, y_vals_3, y_vals_1_label, \\\n",
        "                    y_vals_2_label, y_vals_3_label, x_axis_label, \\\n",
        "                    y_axis_label, title):\n",
        "\n",
        "    plt.plot(x_vals, y_vals_1, color='g', label=y_vals_1_label)\n",
        "    plt.plot(x_vals, y_vals_2, color='orange', label=y_vals_2_label)\n",
        "    plt.plot(x_vals, y_vals_3, color='b', label=y_vals_3_label)\n",
        "    plt.xlabel(x_axis_label)\n",
        "    plt.ylabel(y_axis_label)\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.show()\n",
        "\n",
        "def get_eval_scores(y_test, y_pred):\n",
        "    acc_score = accuracy_score(y_test, y_pred)\n",
        "    pre_score = precision_score(y_test, y_pred)\n",
        "    rec_score = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    return acc_score, pre_score, rec_score, f1\n",
        "\n",
        "# Plot AUC curve\n",
        "def plot_AUC(y_pred_proba, y_test):\n",
        "    pos_score = y_pred_proba[:,1]\n",
        "    fpr, tpr, _ = roc_curve(y_test, pos_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.title('Receiver Operating Characteristic')\n",
        "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "    plt.legend(loc = 'lower right')\n",
        "    plt.plot([0, 1], [0, 1],'r--')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1])\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opWfYxoQktyc"
      },
      "source": [
        "## **Exploratory Data Analysis**\n",
        "\n",
        "Adapted from [here](https://towardsdatascience.com/exploratory-data-analysis-eda-a-practical-guide-and-template-for-structured-data-abfbf3ee3bd9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8K2rkwpBskaP"
      },
      "source": [
        "def time_series_plot(df):\n",
        "    \"\"\"\n",
        "    Given dataframe, generate times series plot of numeric data by daily,\n",
        "    monthly and yearly frequency\n",
        "    \"\"\"\n",
        "    print(\"\\nTo check time series of numeric data  by daily, monthly and yearly frequency\")\n",
        "    if len(df.select_dtypes(include='datetime64').columns)>0:\n",
        "        for col in df.select_dtypes(include='datetime64').columns:\n",
        "            for p in ['D', 'M', 'Y']:\n",
        "                if p=='D':\n",
        "                    print(\"Plotting daily data\")\n",
        "                elif p=='M':\n",
        "                    print(\"Plotting monthly data\")\n",
        "                else:\n",
        "                    print(\"Plotting yearly data\")\n",
        "                for col_num in df.select_dtypes(include=np.number).columns:\n",
        "                    __ = df.copy()\n",
        "                    __ = __.set_index(col)\n",
        "                    __T = __.resample(p).sum()\n",
        "                    ax = __T[[col_num]].plot()\n",
        "                    ax.set_ylim(bottom=0)\n",
        "                    ax.get_yaxis().set_major_formatter(\n",
        "                    matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
        "                    plt.show()\n",
        "\n",
        "                    \n",
        "def numeric_eda(df, hue=None):\n",
        "    \"\"\"Given dataframe, generate EDA of numeric data\"\"\"\n",
        "    print(\"\\nTo check: \\nDistribution of numeric data\")\n",
        "    display(df.describe().T)\n",
        "    columns = df.select_dtypes(include=np.number).columns\n",
        "    figure = plt.figure(figsize=(20, 10))\n",
        "    figure.add_subplot(1, len(columns), 1)\n",
        "    for index, col in enumerate(columns):\n",
        "        if index > 0:\n",
        "            figure.add_subplot(1, len(columns), index + 1)\n",
        "        sns.boxplot(y=col, data=df, boxprops={'facecolor': 'None'})\n",
        "    figure.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    if len(df.select_dtypes(include='category').columns) > 0:\n",
        "        for col_num in df.select_dtypes(include=np.number).columns:\n",
        "            for col in df.select_dtypes(include='category').columns:\n",
        "                fig = sns.catplot(x=col, y=col_num, kind='violin', data=df, height=5, aspect=2)\n",
        "                fig.set_xticklabels(rotation=90)\n",
        "                plt.show()\n",
        "    \n",
        "    # Plot the pairwise joint distributions\n",
        "    print(\"\\nTo check pairwise joint distribution of numeric data\")\n",
        "    if hue==None:\n",
        "        sns.pairplot(df.select_dtypes(include=np.number))\n",
        "    else:\n",
        "        sns.pairplot(df.select_dtypes(include=np.number).join(df[[hue]]), hue=hue)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def top5(df):\n",
        "    \"\"\"Given dataframe, generate top 5 unique values for non-numeric data\"\"\"\n",
        "    columns = df.select_dtypes(include=['object', 'category']).columns\n",
        "    for col in columns:\n",
        "        print(\"Top 5 unique values of \" + col)\n",
        "        print(df[col].value_counts().reset_index().rename(columns={\"index\": col, col: \"Count\"})[\n",
        "              :min(5, len(df[col].value_counts()))])\n",
        "        print(\" \")\n",
        "    \n",
        "    \n",
        "def categorical_eda(df, hue=None):\n",
        "    \"\"\"Given dataframe, generate EDA of categorical data\"\"\"\n",
        "    print(\"\\nTo check: \\nUnique count of non-numeric data\\n\")\n",
        "    print(df.select_dtypes(include=['object', 'category']).nunique())\n",
        "    top5(df)\n",
        "    # Plot count distribution of categorical data\n",
        "    for col in df.select_dtypes(include='category').columns:\n",
        "        fig = sns.catplot(x=col, kind=\"count\", data=df, hue=hue)\n",
        "        fig.set_xticklabels(rotation=90)\n",
        "        plt.show()\n",
        "    \n",
        "\n",
        "def eda(df):\n",
        "    \"\"\"Given dataframe, generate exploratory data analysis\"\"\"\n",
        "    # check that input is pandas dataframe\n",
        "    if type(df) != pd.core.frame.DataFrame:\n",
        "        raise TypeError(\"Only pandas dataframe is allowed as input\")\n",
        "        \n",
        "    # replace field that's entirely space (or empty) with NaN\n",
        "    df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "\n",
        "    print(\"Preview of data:\")\n",
        "    display(df.head(3))\n",
        "\n",
        "    print(\"\\nTo check: \\n (1) Total number of entries \\n (2) Column types \\n (3) Any null values\\n\")\n",
        "    print(df.info())\n",
        "\n",
        "    # generate preview of entries with null values\n",
        "    if len(df[df.isnull().any(axis=1)] != 0):\n",
        "        print(\"\\nPreview of data with null values:\")\n",
        "        display(df[df.isnull().any(axis=1)].head(3))\n",
        "        missingno.matrix(df)\n",
        "        plt.show()\n",
        "\n",
        "    # generate count statistics of duplicate entries\n",
        "    if len(df[df.duplicated()]) > 0:\n",
        "        print(\"\\n***Number of duplicated entries: \", len(df[df.duplicated()]))\n",
        "        display(df[df.duplicated(keep=False)].sort_values(by=list(df.columns)).head())\n",
        "    else:\n",
        "        print(\"\\nNo duplicated entries found\")\n",
        "\n",
        "    # EDA of categorical data\n",
        "    categorical_eda(df)\n",
        "    \n",
        "    # EDA of numeric data\n",
        "    numeric_eda(df)\n",
        "        \n",
        "    # Plot time series plot of numeric data\n",
        "    time_series_plot(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
