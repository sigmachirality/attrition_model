{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WAF Data Challenge",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysxcTOIGiZOb"
      },
      "source": [
        "## **Setup and Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1jUk3uAilAh"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno\n",
        "import random\n",
        "\n",
        "from scipy.io import arff\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.linear_model import LogisticRegression, \\\n",
        "LogisticRegressionCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, \\\n",
        "f1_score, roc_curve, auc\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5rfX98yjVnD"
    },
      "source": [
        "### **Loading Data into Your Environment**\n",
        "1.   Open the file browsing menu by clicking on the tab with a right pointing arrow\n",
        "2.   Upload the csv file containing the employee data to \\content (the default directory)\n",
        "3.   Run the code block below.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmUnUVfMSBt-"
      },
      "source": [
        "#load data into dataframe\n",
        "df = pd.read_csv('./employee_attrition.csv')\n",
        "\n",
        "#coerce object to categorical data\n",
        "cat_cols = []\n",
        "for t, s in df.iteritems():\n",
        "  if str(s.dtype) == 'object' and t != 'Over18' and t != 'Attrition':\n",
        "    df[t] = df[t].astype('category')\n",
        "    cat_cols.append(t)\n",
        "\n",
        "#reorder columns\n",
        "df = df[[c for c in df if c not in ['Attrition', 'Over18']] + ['Attrition']]\n",
        "y = df.iloc[:, -1].values\n",
        "y = np.vectorize(lambda x: 1 if x == \"Yes\" else 0)(y)\n",
        "X = df.iloc[:, :-1]\n",
        "\n",
        "#encode columns\n",
        "X = pd.get_dummies(X, columns=cat_cols)\n",
        "features = [t for t, s in X.iteritems()]\n",
        "X = X.values\n",
        "c_weight = {0: 1, 1: 5}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUqF43QZkAAs"
      },
      "source": [
        "### **Creating Training and Test Sets**\n",
        "We assign 70% of the data into the training set and 30% into the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RquBQYEsld2_"
      },
      "source": [
        "X_norm = StandardScaler().fit_transform(X)\n",
        "\n",
        "# Seperate negative and positive examples\n",
        "X_pos = X[y == 1]\n",
        "y_pos = y[y == 1]\n",
        "X_neg = X[y == 0]\n",
        "y_neg = y[y == 0]\n",
        "\n",
        "# Split full data into training and test sets\n",
        "pos = int(len(y_pos) * 0.7)\n",
        "neg = int(len(y_neg) * 0.7)\n",
        "\n",
        "X_train = np.concatenate((X_neg[:neg], X_pos[:pos]))\n",
        "y_train = np.concatenate((y_neg[:neg], y_pos[:pos]))\n",
        "X_train, y_train = shuffle(X_train, y_train)\n",
        "X_train = StandardScaler().fit_transform(X_train)\n",
        "\n",
        "\n",
        "X_test = np.concatenate((X_neg[neg:], X_pos[pos:]))\n",
        "y_test = np.concatenate((y_neg[neg:], y_pos[pos:]))\n",
        "X_test, y_test = shuffle(X_test, y_test)\n",
        "X_test = StandardScaler().fit_transform(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
